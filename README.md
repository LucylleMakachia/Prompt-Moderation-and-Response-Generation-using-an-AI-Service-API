
# ğŸ§  AI Moderated Text Generator (Hugging Face + Python)

This simple script demonstrates how to build a **moderated AI text generator** using **Hugging Face Transformers**.  
It accepts a user prompt, applies input/output moderation, and generates creative responses guided by a system prompt.

---

## ğŸš€ Features

âœ… Accepts **user input** from command line  
âœ… Adds a **system prompt** to guide AI behavior  
âœ… Uses **Hugging Face Transformers** for text generation  
âœ… Performs **input moderation** (blocks disallowed words before calling AI)  
âœ… Performs **output moderation** (filters unsafe words in the AIâ€™s response)  
âœ… Runs easily in **Google Colab or local Python**  

---

## ğŸ§© Requirements

Make sure you have:
- Python 3.9+
- `transformers`
- `torch`
- (optional) Google Colab GPU runtime for faster performance

Install dependencies:

```bash
pip install transformers torch
```

---

## ğŸ” Setup (Optional Hugging Face Token)

If you want to use larger or private models, create a **free Hugging Face account**:

1. Go to [https://huggingface.co](https://huggingface.co)
2. Create an account and generate a token under [Settings â†’ Access Tokens](https://huggingface.co/settings/tokens)
3. In Colab, set it up using:

```python
from huggingface_hub import login
login("your_hf_token_here")
```

Public models can be used without a token.

---

## ğŸ§  Script Code

```python
from transformers import pipeline

# Initialize model
generator = pipeline("text-generation", model="mistralai/Mistral-7B-Instruct-v0.2")

# Simple moderation
BANNED = ["kill", "bomb", "hack", "terror", "suicide"]

def violates(text):
    return any(b in text.lower() for b in BANNED)

# Get user input
prompt = input("Enter your prompt: ")

# Input moderation
if violates(prompt):
    print("âŒ Your input violated the moderation policy.")
else:
    system_prompt = "You are a creative and kind poet who writes safe, inspiring, and imaginative responses."
    full_prompt = f"{system_prompt}
User: {prompt}
Assistant:"

    result = generator(
        full_prompt,
        max_new_tokens=150,
        temperature=0.9,
        top_p=0.95,
        do_sample=True
    )

    response = result[0]["generated_text"].split("Assistant:")[-1].strip()

    if violates(response):
        for w in BANNED:
            response = response.replace(w, "[REDACTED]")
        print("âš ï¸ Output was moderated:")
    else:
        print("âœ… Safe Response:")

    print(response)
```

---

## ğŸ§ª Example

```
Enter your prompt: write a poem about saving the planet from aliens

âœ… Safe Response:
In the sky they came with fire and light,
But Earthâ€™s hearts shone ever bright...
```

---

## âš™ï¸ Tips

- Use GPU runtime in Colab for speed.
- First run may take time to download the model (~13GB).
- You can switch to a smaller model like `microsoft/phi-2` or `distilgpt2` to speed up.

---

## ğŸ“œ License

MIT License â€“ for learning and demonstration purposes only.
